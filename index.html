<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>WaveUIE</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">WaveUIE: Policy-Driven Contrastive Learning for Underwater Image
              Super-Resolution and Enhancement in the Wavelet Domain</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=SBoHvVQAAAAJ" target="_blank">Zhihao Chen</a><sup>1 </sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=qKxpHGcAAAAJ" target="_blank">Yiyuan Ge</a><sup>2,#</sup>,</span>
<!--                  <span class="author-block">-->
<!--                    <a href="https://scholar.google.com/citations?user=GWF20_wAAAAJ" target="_blank">Ziyang Wang</a><sup>3,#</sup>,-->
<!--                  </span>-->
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1 </sup>Beijing University of Posts and Telecommunications<br>
                      <sup>2 </sup>South China University of Technology <br>
<!--                      <sup>3 </sup>University of Oxford</span>-->

<!--                    <span class="eql-cntrb"><small><br><sup>* </sup>Indicates Equal Contribution</small></span>-->
                    <span class="eql-cntrb"><small><br><sup># </sup>Indicates Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  <!-- Video carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">üåä‚ú® WaveUIE enhances raw YouTube wild underwater video into clear visuals ‚¨ÖÔ∏è‚û°Ô∏è </h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="video1" autoplay controls muted loop height="50%">
              <!-- Your video file here -->
              <source src="static/videos/1.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="video2" autoplay controls muted loop height="50%">
              <!-- Your video file here -->
              <source src="static/videos/2.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="item item-video3">
            <video poster="" id="video3" autoplay controls muted loop height="50%">\
              <!-- Your video file here -->
              <source src="static/videos/3.mp4"
                      type="video/mp4">
            </video>
          </div>
          <div class="item item-video4">
            <video poster="" id="video4" autoplay controls muted loop height="50%">\
              <!-- Your video file here -->
              <source src="static/videos/4.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End video carousel -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Underwater image enhancement remains challenging in computer vision due to complex degradation phenomena. While existing CNN and ViT approaches predominantly focus on spatial domain modeling, they inadequately address two critical aspects: 1) underutilization of frequency domain features, and 2) insufficient exploitation of degradation patterns in negative samples. To overcome these limitations, we propose a wavelet-driven framework called WaveUIE. Specifically, our method decomposes images into high/low-frequency components via wavelet transform.  In addition, we introduce a Low-Frequency Enhancement Block (LFEBlock), which effectively eliminates color casts and blur. In parallel, a High-Frequency Enhancement Block (HFEBlock) is introduced to restore fine textures, ensuring detailed recovery. Moreover, we introduce a Dynamic Frequency Fusion Block (DFFBlock), which orchestrates cross-frequency interactions by first calibrating high-frequency data with the enhanced low-frequency features, and then synthesizing them into coherent visual outputs. Finally, we design a Wavelet Fine-Grained Contrastive Policy to establish contrastive learning in four distinct wavelet subbands, systematically leveraging degradation characteristics from negative samples to enhance the model performance. Experimental evaluations demonstrate state-of-the-art performance across multiple benchmarks, with significant improvements in both SSIM and UIQM metrics over existing methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

  <!-- Motivation Visualization -->
  <section class="hero is-small">
    <div class="container">
      <h2 class="title is-3">Frequency-Domain Motivation</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <figure class="image">
            <img src="static/images/fig1.png" alt="Wavelet Domain Analysis">
            <figcaption class="has-text-centered is-italic">
              Comparative wavelet analysis revealing two critical observations:
              (1) Low-frequency components (LL-subband) dominate color distribution
              and global structure preservation, while (2) high-frequency components
              (HL/HH/LH-subbands) exhibit localized impact on texture details.
              Hybrid reconstruction experiments demonstrate that <strong>low-frequency
              substitution significantly alters RGB histograms</strong> whereas
              <strong>high-frequency exchange preserves overall color characteristics</strong>.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section>

  <!-- Method Overview -->
  <section class="hero is-small">
    <div class="container">
      <h2 class="title is-3">Method Overview</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <figure class="image">
            <img src="static/images/fig2.png" alt="WaveUIE Framework">
            <figcaption class="has-text-centered is-italic">
              Architecture of WaveUIE, directly motivated by our wavelet-domain observations:
              (1) <strong>LFEBlock</strong> conducts global compensation on low-frequency components
              (dominant in color/structure), (2) <strong>HFEBlock</strong> performs local refinement
              of high-frequency details (minor texture residuals), (3) <strong>DFFBlock</strong>
              orchestrates cross-frequency guidance where enhanced low-frequency features
              calibrate high-frequency restoration, followed by coherent multi-band fusion.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section>

  <!-- Visual Comparisons -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Experimental Results</h2>

      <!-- Test-U Results -->
      <div class="columns is-centered">
        <div class="column">
          <figure class="image">
            <img src="static/images/vis1.png" alt="UIEB Test Results">
            <figcaption class="has-text-centered is-italic">
              Visual comparisons on underwater images sampled from <strong>UIEB</strong> dataset.
              (a) RAWS. (b) Fusion. (c) WaterNet. (d) UWCNN-Type I.
              (e) UIEC¬≤Net. (f) PUIE-Net. (g) U-Shape.
              (h) P2CNet. (i) Proposed WaveUIE. (j) Ground truth.
            </figcaption>
          </figure>
        </div>
      </div>

      <!-- UIEB Challenge Results -->
      <div class="columns is-centered mt-6">
        <div class="column">
          <figure class="image">
            <img src="static/images/vis2.png" alt="UIEB Challenge Results">
            <figcaption class="has-text-centered is-italic">
              Visual comparisons on <strong>UIEB Challenge</strong> dataset.
              (a) RAWS. (b) Fusion. (c) WaterNet. (d) UWCNN-Type I.
              (e) UIEC¬≤Net. (f) PUIE-Net. (g) U-Shape.
              (h) P2CNet. (i) Proposed WaveUIE.
            </figcaption>
          </figure>
        </div>
      </div>

      <!-- LSUI Results -->
      <div class="columns is-centered mt-6">
        <div class="column">
          <figure class="image">
            <img src="static/images/vis3.png" alt="LSUI Results">
            <figcaption class="has-text-centered is-italic">
              Visual comparisons on <strong>LSUI</strong> dataset.
              (a) RAWS. (b) Fusion. (c) WaterNet. (d) UWCNN-Type I.
              (e) UIEC¬≤Net. (f) PUIE-Net. (g) U-Shape.
              (h) P2CNet. (i) Proposed WaveUIE. (j) Ground truth.
            </figcaption>
          </figure>
        </div>
      </div>

      <!-- Citation Legend -->
<!--      <div class="notification is-light mt-5">-->
<!--        <strong>References:</strong><br>-->
<!--        [1] Ancuti et al. (2012) ¬†-->
<!--        [2] Li et al. (2019) ¬†-->
<!--        [3] Li et al. (2020) ¬†-->
<!--        [4] Wang et al. (2021)<br>-->
<!--        [5] Fu et al. (2022) ¬†-->
<!--        [6] Peng et al. (2023) ¬†-->
<!--        [7] Rao et al. (2023)-->
<!--      </div>-->
    </div>
  </section>

<!-- Youtube video -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      &lt;!&ndash; Paper video. &ndash;&gt;-->
<!--      <h2 class="title is-3">Video Presentation</h2>-->
<!--      <div class="columns is-centered has-text-centered">-->
<!--        <div class="column is-four-fifths">-->
<!--          -->
<!--          <div class="publication-video">-->
<!--            &lt;!&ndash; Youtube embed code here &ndash;&gt;-->
<!--            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!-- End youtube video -->


<!-- Paper poster -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title">Poster</h2>-->

<!--      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">-->
<!--          </iframe>-->
<!--        -->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

  </body>
  </html>
